import base64
import datetime
import gc
import hashlib
import logging
import os
import pickle
import random
import socket
import sys
import time

from   math import sqrt

import mccache as mc

# Callback method for key that are updated within 1 second of lookup in the background.
#
def test_callback(ctx: dict) -> bool:
    """Callback method to be notified of changes within one second of previous lookup.

    Args:
        ctx :dict   A context dictionary of the following format:
                    {
                        typ:    Type of alert. 1=Deletion ,2=Update ,3=Incoherence
                        nms:    Cache namespace.
                        key:    Identifying key.
                        lkp:    Lookup timestamp.
                        tsm:    Current entry timestamp.
                        elp:    Elapsed time.
                        prvcrc: Previous value CRC.
                        newcrc: Current  value CRC.
                    }
    """
    # DEBUG trace.
    if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.BASIC:
        match ctx['typ']:
            case 1: # Deletion
                mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.WRN ,tsm=time.time_ns() ,nms=ctx['nms'] ,key=ctx['key'] ,crc=ctx['newcrc']
                                                ,msg=f"^   WRN {ctx['key']} got deleted within {ctx['elp']:0.5f} sec in the background." )
            case 2: # Updates
                mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.WRN ,tsm=time.time_ns() ,nms=ctx['nms'] ,key=ctx['key'] ,crc=ctx['newcrc']
                                                ,msg=f"^   WRN {ctx['key']} got updated within {ctx['elp']:0.5f} sec in the background." )
    return  True


# Initialization section.
#
# SEE:  https://stackoverflow.com/questions/43357278/how-can-i-make-time-sleep-shorter
#   minsleep = 0.01
#   for f in [ 0.003 ,0.002 ,0.001 ,0.0008 ,0.0006 ,0.0004 ,0.0002 ,0.00008 ,0.00006 ,0.00004 ,0.00002 ]:
#       time.sleep( 1 )
#       bgn = datetime.datetime.now()
#       time.sleep( f )
#       end = datetime.datetime.now()
#       dif = end - bgn
#       if  dif.total_seconds() > f*1.29:
#           #   print(f" {f:<6}: {dif.total_seconds():<8} > {f*1.29:<8}")
#           break
#       #   print(f" {f:<6}: {dif.total_seconds():<8} < {f*1.29:<8}")
#       minsleep = f
#   mc.logger.info(f"Python time.sleep( {minsleep} ) is the smallest aperture for this machine.")

rndseed = 17
if 'TEST_RANDOM_SEED' in os.environ:
    rndseed = int(os.environ['TEST_RANDOM_SEED'])
else:
    rndseed = int(str(socket.getaddrinfo(socket.gethostname() ,0 ,socket.AF_INET )[0][4][0]).split(".")[3])
random.seed( rndseed )

# The artificial pauses in between cache operation.  Targeting between 10 to 30 ms.
# SEE: https://www.centurylink.com/home/help/internet/how-to-improve-gaming-latency.html
#
sleepmax:float= 2   if 'TEST_SLEEP_MAX'     not in os.environ else float(os.environ['TEST_SLEEP_MAX']  )
sleepapt:int  = 100 if 'TEST_SLEEP_APT'     not in os.environ else int(  os.environ['TEST_SLEEP_APT']  )

entries:int   = 200 if 'TEST_MAX_ENTRIES'   not in os.environ else int(  os.environ['TEST_MAX_ENTRIES'])
duration:int  = 5   if 'TEST_RUN_DURATION'  not in os.environ else int(  os.environ['TEST_RUN_DURATION'])#

if  mc._mcConfig.callback_win < 0.1:    # Only this tight in testing.
    cache = mc.get_cache( callback=test_callback )
else:
    cache = mc.get_cache( callback=None )

bgn = time.time()
end = time.time()
frg = '{'+'frg:0{l}'.format( l=len(str( entries )))+'}'

# Random test section.
#
mc.logger.info(f"{mc.SRC_IP_ADD} Config: Seed={rndseed:3}  ,CBck={mc._mcConfig.callback_win:2} sec ,Duration={duration:2} min ,Keys={entries:3} ,SMax={sleepmax} ,SApt={sleepapt}")

# NOTE: We are targeting 10-50% ms fair latency.  https://www.centurylink.com/home/help/internet/how-to-improve-gaming-latency.html#:~:text=Low%20latency%20means%20less%20lag,a%20noticeable%20lag%20in%20gaming.

ctr:int = 0     # Counter
while (end - bgn) < (duration*60):  # Seconds.
    # SEE: https://stackoverflow.com/questions/1133857/how-accurate-is-pythons-time-sleep (1ms)
    snooze = random.randrange(1 ,int(sleepmax*sleepapt) ,10) / (sleepapt*sleepapt/10)
    time.sleep( snooze )
    if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.SUPERFLUOUS:
        elp = time.time() - end
        glp = '~' if abs((elp - snooze) / snooze) < 0.335 else '!'  # 33% Glyph.
        mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.FYI ,tsm=time.time_ns() ,nms=cache.name ,key=' '*8
                                        ,msg=f">   {round(elp ,5):0.5f} {glp} {round(snooze ,5):0.5f} sec paused in test script." )

    rnd = random.randint( 0 ,entries )
    seg = frg.format( frg=rnd )

    if  random.randint(0 ,20) == 5: # Arbitrarily 5% is strictly to be only generate on this node.
        # Keys unique to this node.
        key = f'K{mc.SRC_IP_SEQ:03}-{seg}'
    else:
        # Keys can be generated by every nodes.
        key = f'K000-{seg}'

    ctr +=  1
    opc =   random.randint( 0 ,20 )
    match   opc:
        case 0:
            pass
        case 1|2|3|4:   # NOTE: 20% are inserts.
            if  key not in cache:
                val = (mc.SRC_IP_SEQ ,datetime.datetime.now(datetime.UTC) ,ctr) # The minimum fields to totally randomize the value.
                pkl: bytes = pickle.dumps( val )
                crc: str   = base64.b64encode( hashlib.md5( pkl ).digest() ).decode()  # noqa: S324

                # DEBUG trace.
                if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.EXTRA:
                    mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.INS ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc[:-2]
                                                    ,msg=f">   INS {key}={val} in test script." )

                # Insert cache entry.
                cache[ key ] = val

                # DEBUG trace.
                if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.SUPERFLUOUS:
                    if  key not in cache:
                        mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.INS ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                        ,msg=f">   ERR:{key} NOT persisted in cache in test script!" )
                    else:
                        try:
                            if  val != cache[ key ]:
                                mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.INS ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                                ,msg=f">   ERR:{key} value is incoherent in cache in test script!" )
                            else:
                                mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.INS ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                                ,msg=f">   OK: {key} persisted in cache in test script." )
                        except KeyError:
                            mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.INS ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                            ,msg=f">   ERR:{key} Not found in cache in test script." )

        case 5|6|7|8:   # NOTE: 20% are updates.
            if  key in cache:
                val = (mc.SRC_IP_SEQ ,datetime.datetime.now(datetime.UTC) ,ctr) # The minimum fields to totally randomize the value.
                pkl: bytes = pickle.dumps( val )
                crc: str   = base64.b64encode( hashlib.md5( pkl ).digest() ).decode()   # noqa: S324

                # DEBUG trace.
                if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.EXTRA:
                    mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.UPD ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc[:-2]
                                                    ,msg=f">   UPD {key}={val} in test script." )

                # Update cache entry.
                cache[ key ] = val

                # DEBUG trace.
                if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.SUPERFLUOUS:
                    if  key not in cache:
                        mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.UPD ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                        ,msg=f">   ERR:{key} NOT persisted in cache in test script!" )
                    else:
                        if  val != cache[ key ]:
                            mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.UPD ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                            ,msg=f">   ERR:{key} value is incoherent in test script!" )
                        else:
                            mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.UPD ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                            ,msg=f">   OK: {key} persisted in cache in test script!" )
        case 9:     # NOTE: 5% are deletes.
            if  key in cache:
                # Evict cache.
                try:
                    # DEBUG trace.
                    if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.EXTRA:
                        mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.DEL ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                        ,msg=f">   DEL {key} in test script." )
                    # Delete cache entry.
                    crc =  cache.metadata[ key ]['crc']

                    # DEBUG trace.
                    if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.SUPERFLUOUS:
                        mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.DEL ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                        ,msg=f">   DEL {key} in test script." )

                    del cache[ key ]
                except KeyError:
                    pass

                # DEBUG trace.
                if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.SUPERFLUOUS:
                    if  key in cache:
                        mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.DEL ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                        ,msg=f">   ERR:{key} still persist in cache in test script!" )
                    else:
                        mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.DEL ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=crc
                                                        ,msg=f">   OK: {key} deleted from cache in test script." )
        case _:     # NOTE: 55% are lookups.
            # Look up cache.
            val = cache.get( key ,None )

            # DEBUG trace.
            if  mc._mcConfig.debug_level >= mc.McCacheDebugLevel.SUPERFLUOUS:
                if  not val:
                    mc._log_ops_msg( logging.DEBUG  ,opc=mc.OpCode.FYI ,tsm=time.time_ns() ,nms=cache.name ,key=key ,crc=None
                                                    ,msg=f">   WRN:{key} not in cache in test script!")
    end = time.time()

# Done stress testing.
#

# All incoming updates after the the following "Done." cutoff should be discarded.
#
# Lock to take a snapshot.
mc._lock.acquire()
mc._log_ops_msg( logging.INFO   ,opc=mc.OpCode.FYI ,tsm=cache.TSM_VERSION() ,nms=cache.name ,msg=f"Done testing. Querying final cache checksum." )

# Wait for some straggler to trickle in before to dump out the cache.
time.sleep( 1 )

# Query the local cache and metrics and exit.
#
mc.get_cache_checksum( name=cache.name ,node=mc.SRC_IP_ADD )
mc.get_cluster_metrics( mc.SRC_IP_ADD )

mc._log_ops_msg( logging.INFO   ,opc=mc.OpCode.FYI ,tsm=cache.TSM_VERSION() ,nms=cache.name ,msg=f"Exiting test." )
mc._lock.release()
